{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7004a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=1.5.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 4)) (1.6.1)\n",
      "Requirement already satisfied: langgraph>=0.0.50 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (0.3.1)\n",
      "Requirement already satisfied: langchain>=0.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (0.3.19)\n",
      "Requirement already satisfied: langchain-openai>=0.0.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 9)) (0.3.7)\n",
      "Requirement already satisfied: scipy>=1.9.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 12)) (1.15.2)\n",
      "Collecting statsmodels>=0.13.0 (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 13))\n",
      "  Downloading statsmodels-0.14.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: shap>=0.41.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16)) (0.48.0)\n",
      "Requirement already satisfied: lime>=0.2.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 17)) (0.2.0.1)\n",
      "Collecting dowhy>=0.8.0 (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 20))\n",
      "  Downloading dowhy-0.8-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting econml>=0.13.0 (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 21))\n",
      "  Downloading econml-0.15.1.tar.gz (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pymc>=5.0.0 (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24))\n",
      "  Downloading pymc-5.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting arviz>=0.12.0 (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 25))\n",
      "  Downloading arviz-0.21.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 28)) (3.10.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 29)) (0.13.2)\n",
      "Requirement already satisfied: requests>=2.28.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 32)) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv>=0.19.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 33)) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=1.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=1.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=1.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from scikit-learn>=1.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from scikit-learn>=1.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (0.3.40)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (2.0.16)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (0.1.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (0.1.53)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (2.0.38)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (9.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain-openai>=0.0.5->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 9)) (1.65.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain-openai>=0.0.5->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 9)) (0.9.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 13))\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from statsmodels>=0.13.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 13)) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from shap>=0.41.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16)) (4.67.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from shap>=0.41.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16)) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from shap>=0.41.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16)) (0.61.2)\n",
      "Requirement already satisfied: cloudpickle in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from shap>=0.41.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16)) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from shap>=0.41.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16)) (4.14.0)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from lime>=0.2.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 17)) (0.25.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from dowhy>=0.8.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 20)) (3.4.2)\n",
      "Requirement already satisfied: sympy>=1.4 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from dowhy>=0.8.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 20)) (1.13.1)\n",
      "Collecting pydot>=1.4 (from dowhy>=0.8.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 20))\n",
      "  Downloading pydot-4.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy>=1.21.0 (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 3))\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-learn>=1.1.0 (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 4))\n",
      "  Downloading scikit_learn-1.5.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting sparse (from econml>=0.13.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 21))\n",
      "  Downloading sparse-0.17.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shap>=0.41.0 (from -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16))\n",
      "  Downloading shap-0.43.0.tar.gz (389 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lightgbm (from econml>=0.13.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 21))\n",
      "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Collecting slicer==0.0.7 (from shap>=0.41.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16))\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: cachetools>=4.2.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24)) (5.5.2)\n",
      "Collecting pytensor<2.32,>=2.31.2 (from pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24))\n",
      "  Downloading pytensor-2.31.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: rich>=13.7.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24)) (13.9.4)\n",
      "Requirement already satisfied: setuptools>=60.0.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz>=0.12.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 25)) (75.8.2)\n",
      "Collecting xarray>=2022.6.0 (from arviz>=0.12.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 25))\n",
      "  Downloading xarray-2025.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting h5netcdf>=1.0.2 (from arviz>=0.12.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 25))\n",
      "  Downloading h5netcdf-1.6.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting xarray-einstats>=0.3 (from arviz>=0.12.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 25))\n",
      "  Downloading xarray_einstats-0.9.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 28)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 28)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 28)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 28)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 28)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 28)) (3.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from requests>=2.28.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 32)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from requests>=2.28.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 32)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from requests>=2.28.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 32)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from requests>=2.28.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 32)) (2025.1.31)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (1.18.3)\n",
      "Collecting h5py (from h5netcdf>=1.0.2->arviz>=0.12.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 25))\n",
      "  Downloading h5py-3.14.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langchain-core<0.4,>=0.1->langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.0.5->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 9)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.0.5->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.0.5->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 9)) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai>=0.0.5->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (2.27.2)\n",
      "Requirement already satisfied: filelock>=3.15 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pytensor<2.32,>=2.31.2->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24)) (3.17.0)\n",
      "Collecting etuples (from pytensor<2.32,>=2.31.2->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24))\n",
      "  Downloading etuples-0.3.9.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting logical-unification (from pytensor<2.32,>=2.31.2->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24))\n",
      "  Downloading logical-unification-0.4.6.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting miniKanren!=1.0.4 (from pytensor<2.32,>=2.31.2->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24))\n",
      "  Downloading minikanren-1.0.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting cons (from pytensor<2.32,>=2.31.2->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24))\n",
      "  Downloading cons-0.4.6.tar.gz (26 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from rich>=13.7.1->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from rich>=13.7.1->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24)) (2.19.1)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from scikit-image>=0.12->lime>=0.2.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 17)) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from scikit-image>=0.12->lime>=0.2.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 17)) (2025.6.11)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from scikit-image>=0.12->lime>=0.2.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 17)) (0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 8)) (3.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from sympy>=1.4->dowhy>=0.8.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 20)) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.0.5->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 9)) (2024.11.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from numba>=0.54->shap>=0.41.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 16)) (0.44.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph>=0.0.50->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24)) (0.1.2)\n",
      "Collecting multipledispatch (from miniKanren!=1.0.4->pytensor<2.32,>=2.31.2->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24))\n",
      "  Downloading multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting toolz (from miniKanren!=1.0.4->pytensor<2.32,>=2.31.2->pymc>=5.0.0->-r /home/danilo/repos/statistical_agent_medical_data/requirements.txt (line 24))\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading statsmodels-0.14.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dowhy-0.8-py3-none-any.whl (287 kB)\n",
      "Downloading scikit_learn-1.5.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Downloading pymc-5.23.0-py3-none-any.whl (519 kB)\n",
      "Downloading arviz-0.21.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5netcdf-1.6.2-py3-none-any.whl (50 kB)\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading pydot-4.0.1-py3-none-any.whl (37 kB)\n",
      "Downloading pytensor-2.31.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xarray-2025.6.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xarray_einstats-0.9.1-py3-none-any.whl (39 kB)\n",
      "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sparse-0.17.0-py2.py3-none-any.whl (259 kB)\n",
      "Downloading minikanren-1.0.5-py3-none-any.whl (24 kB)\n",
      "Downloading h5py-3.14.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Building wheels for collected packages: econml, numpy, shap, cons, etuples, logical-unification\n",
      "  Building wheel for econml (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for econml \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[292 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-wz_0rwaw/overlay/lib/python3.13/site-packages/setuptools/config/_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   corresp(dist, value, root_dir)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-wz_0rwaw/overlay/lib/python3.13/site-packages/setuptools/config/_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: MIT License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-wz_0rwaw/overlay/lib/python3.13/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: MIT License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/__init__.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/_cate_estimator.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/_ortho_learner.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/_shap.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/_tree_exporter.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/_version.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/dowhy.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/federated_learning.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m copying econml/utilities.py -> build/lib.linux-x86_64-cpython-313/econml\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/_ensemble\n",
      "  \u001b[31m   \u001b[0m copying econml/_ensemble/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/_ensemble\n",
      "  \u001b[31m   \u001b[0m copying econml/_ensemble/_ensemble.py -> build/lib.linux-x86_64-cpython-313/econml/_ensemble\n",
      "  \u001b[31m   \u001b[0m copying econml/_ensemble/_utilities.py -> build/lib.linux-x86_64-cpython-313/econml/_ensemble\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/automated_ml\n",
      "  \u001b[31m   \u001b[0m copying econml/automated_ml/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/automated_ml\n",
      "  \u001b[31m   \u001b[0m copying econml/automated_ml/_automated_ml.py -> build/lib.linux-x86_64-cpython-313/econml/automated_ml\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/cate_interpreter\n",
      "  \u001b[31m   \u001b[0m copying econml/cate_interpreter/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/cate_interpreter\n",
      "  \u001b[31m   \u001b[0m copying econml/cate_interpreter/_interpreters.py -> build/lib.linux-x86_64-cpython-313/econml/cate_interpreter\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/data\n",
      "  \u001b[31m   \u001b[0m copying econml/data/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/data\n",
      "  \u001b[31m   \u001b[0m copying econml/data/dgps.py -> build/lib.linux-x86_64-cpython-313/econml/data\n",
      "  \u001b[31m   \u001b[0m copying econml/data/dynamic_panel_dgp.py -> build/lib.linux-x86_64-cpython-313/econml/data\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/dml\n",
      "  \u001b[31m   \u001b[0m copying econml/dml/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/dml\n",
      "  \u001b[31m   \u001b[0m copying econml/dml/_rlearner.py -> build/lib.linux-x86_64-cpython-313/econml/dml\n",
      "  \u001b[31m   \u001b[0m copying econml/dml/causal_forest.py -> build/lib.linux-x86_64-cpython-313/econml/dml\n",
      "  \u001b[31m   \u001b[0m copying econml/dml/dml.py -> build/lib.linux-x86_64-cpython-313/econml/dml\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/dr\n",
      "  \u001b[31m   \u001b[0m copying econml/dr/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/dr\n",
      "  \u001b[31m   \u001b[0m copying econml/dr/_drlearner.py -> build/lib.linux-x86_64-cpython-313/econml/dr\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/grf\n",
      "  \u001b[31m   \u001b[0m copying econml/grf/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/grf\n",
      "  \u001b[31m   \u001b[0m copying econml/grf/_base_grf.py -> build/lib.linux-x86_64-cpython-313/econml/grf\n",
      "  \u001b[31m   \u001b[0m copying econml/grf/_base_grftree.py -> build/lib.linux-x86_64-cpython-313/econml/grf\n",
      "  \u001b[31m   \u001b[0m copying econml/grf/classes.py -> build/lib.linux-x86_64-cpython-313/econml/grf\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/inference\n",
      "  \u001b[31m   \u001b[0m copying econml/inference/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/inference\n",
      "  \u001b[31m   \u001b[0m copying econml/inference/_bootstrap.py -> build/lib.linux-x86_64-cpython-313/econml/inference\n",
      "  \u001b[31m   \u001b[0m copying econml/inference/_inference.py -> build/lib.linux-x86_64-cpython-313/econml/inference\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/iv\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/iv\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/metalearners\n",
      "  \u001b[31m   \u001b[0m copying econml/metalearners/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/metalearners\n",
      "  \u001b[31m   \u001b[0m copying econml/metalearners/_metalearners.py -> build/lib.linux-x86_64-cpython-313/econml/metalearners\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/orf\n",
      "  \u001b[31m   \u001b[0m copying econml/orf/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/orf\n",
      "  \u001b[31m   \u001b[0m copying econml/orf/_causal_tree.py -> build/lib.linux-x86_64-cpython-313/econml/orf\n",
      "  \u001b[31m   \u001b[0m copying econml/orf/_ortho_forest.py -> build/lib.linux-x86_64-cpython-313/econml/orf\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/panel\n",
      "  \u001b[31m   \u001b[0m copying econml/panel/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/panel\n",
      "  \u001b[31m   \u001b[0m copying econml/panel/utilities.py -> build/lib.linux-x86_64-cpython-313/econml/panel\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/policy\n",
      "  \u001b[31m   \u001b[0m copying econml/policy/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/policy\n",
      "  \u001b[31m   \u001b[0m copying econml/policy/_base.py -> build/lib.linux-x86_64-cpython-313/econml/policy\n",
      "  \u001b[31m   \u001b[0m copying econml/policy/_drlearner.py -> build/lib.linux-x86_64-cpython-313/econml/policy\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/score\n",
      "  \u001b[31m   \u001b[0m copying econml/score/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/score\n",
      "  \u001b[31m   \u001b[0m copying econml/score/ensemble_cate.py -> build/lib.linux-x86_64-cpython-313/econml/score\n",
      "  \u001b[31m   \u001b[0m copying econml/score/rscorer.py -> build/lib.linux-x86_64-cpython-313/econml/score\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/sklearn_extensions\n",
      "  \u001b[31m   \u001b[0m copying econml/sklearn_extensions/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/sklearn_extensions\n",
      "  \u001b[31m   \u001b[0m copying econml/sklearn_extensions/linear_model.py -> build/lib.linux-x86_64-cpython-313/econml/sklearn_extensions\n",
      "  \u001b[31m   \u001b[0m copying econml/sklearn_extensions/model_selection.py -> build/lib.linux-x86_64-cpython-313/econml/sklearn_extensions\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/tree\n",
      "  \u001b[31m   \u001b[0m copying econml/tree/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/tree\n",
      "  \u001b[31m   \u001b[0m copying econml/tree/_tree_classes.py -> build/lib.linux-x86_64-cpython-313/econml/tree\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/validate\n",
      "  \u001b[31m   \u001b[0m copying econml/validate/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/validate\n",
      "  \u001b[31m   \u001b[0m copying econml/validate/drtester.py -> build/lib.linux-x86_64-cpython-313/econml/validate\n",
      "  \u001b[31m   \u001b[0m copying econml/validate/results.py -> build/lib.linux-x86_64-cpython-313/econml/validate\n",
      "  \u001b[31m   \u001b[0m copying econml/validate/utils.py -> build/lib.linux-x86_64-cpython-313/econml/validate\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/iv/dml\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/dml/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/iv/dml\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/dml/_dml.py -> build/lib.linux-x86_64-cpython-313/econml/iv/dml\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/iv/dr\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/dr/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/iv/dr\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/dr/_dr.py -> build/lib.linux-x86_64-cpython-313/econml/iv/dr\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/iv/nnet\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/nnet/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/iv/nnet\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/nnet/_deepiv.py -> build/lib.linux-x86_64-cpython-313/econml/iv/nnet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/iv/sieve\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/sieve/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/iv/sieve\n",
      "  \u001b[31m   \u001b[0m copying econml/iv/sieve/_tsls.py -> build/lib.linux-x86_64-cpython-313/econml/iv/sieve\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/panel/dml\n",
      "  \u001b[31m   \u001b[0m copying econml/panel/dml/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/panel/dml\n",
      "  \u001b[31m   \u001b[0m copying econml/panel/dml/_dml.py -> build/lib.linux-x86_64-cpython-313/econml/panel/dml\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/policy/_forest\n",
      "  \u001b[31m   \u001b[0m copying econml/policy/_forest/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/policy/_forest\n",
      "  \u001b[31m   \u001b[0m copying econml/policy/_forest/_forest.py -> build/lib.linux-x86_64-cpython-313/econml/policy/_forest\n",
      "  \u001b[31m   \u001b[0m copying econml/policy/_forest/_tree.py -> build/lib.linux-x86_64-cpython-313/econml/policy/_forest\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/solutions/causal_analysis\n",
      "  \u001b[31m   \u001b[0m copying econml/solutions/causal_analysis/__init__.py -> build/lib.linux-x86_64-cpython-313/econml/solutions/causal_analysis\n",
      "  \u001b[31m   \u001b[0m copying econml/solutions/causal_analysis/_causal_analysis.py -> build/lib.linux-x86_64-cpython-313/econml/solutions/causal_analysis\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing econml.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to econml.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to econml.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to econml.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'econml.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'econml.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying econml/grf/_criterion.c -> build/lib.linux-x86_64-cpython-313/econml/grf\n",
      "  \u001b[31m   \u001b[0m copying econml/grf/_utils.c -> build/lib.linux-x86_64-cpython-313/econml/grf\n",
      "  \u001b[31m   \u001b[0m copying econml/tree/_criterion.c -> build/lib.linux-x86_64-cpython-313/econml/tree\n",
      "  \u001b[31m   \u001b[0m copying econml/tree/_splitter.c -> build/lib.linux-x86_64-cpython-313/econml/tree\n",
      "  \u001b[31m   \u001b[0m copying econml/tree/_tree.c -> build/lib.linux-x86_64-cpython-313/econml/tree\n",
      "  \u001b[31m   \u001b[0m copying econml/tree/_utils.c -> build/lib.linux-x86_64-cpython-313/econml/tree\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/data/ihdp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/ihdp/example.csv -> build/lib.linux-x86_64-cpython-313/econml/data/ihdp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/ihdp/example_full.csv -> build/lib.linux-x86_64-cpython-313/econml/data/ihdp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/ihdp/sim.csv -> build/lib.linux-x86_64-cpython-313/econml/data/ihdp\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/cov_new.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/gm_0.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/gm_1.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/gm_2.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/gm_3.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/gm_4.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/gm_5.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/gm_6.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_neg_0.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_neg_1.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_neg_2.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_neg_3.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_neg_4.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_neg_5.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_pos_0.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_pos_1.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_pos_2.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_pos_3.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_pos_4.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_pos_5.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/lognorm_pos_6.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/n_0.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/n_1.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/n_2.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/n_3.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/n_4.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/n_5.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/data/input_dynamicdgp/n_6.jbl -> build/lib.linux-x86_64-cpython-313/econml/data/input_dynamicdgp\n",
      "  \u001b[31m   \u001b[0m copying econml/policy/_forest/_criterion.c -> build/lib.linux-x86_64-cpython-313/econml/policy/_forest\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'econml.grf._criterion' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-313/econml/grf\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /home/danilo/anaconda3/envs/mestrado/shared/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/danilo/anaconda3/envs/mestrado/include -fPIC -O2 -isystem /home/danilo/anaconda3/envs/mestrado/include -fPIC -I/tmp/pip-build-env-wz_0rwaw/overlay/lib/python3.13/site-packages/numpy/_core/include -I/home/danilo/anaconda3/envs/mestrado/include/python3.13 -c econml/grf/_criterion.c -o build/temp.linux-x86_64-cpython-313/econml/grf/_criterion.o\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:861:1: warning: ‘Py_UNICODE’ is deprecated [-Wdeprecated-declarations]\n",
      "  \u001b[31m   \u001b[0m   861 | static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {\n",
      "  \u001b[31m   \u001b[0m       | ^~~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__Pyx_Py_UNICODE_strlen’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:862:5: warning: ‘Py_UNICODE’ is deprecated [-Wdeprecated-declarations]\n",
      "  \u001b[31m   \u001b[0m   862 |     const Py_UNICODE *u_end = u;\n",
      "  \u001b[31m   \u001b[0m       |     ^~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__Pyx_PyList_Extend’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:2507:22: error: implicit declaration of function ‘_PyList_Extend’; did you mean ‘PyList_Extend’? [-Wimplicit-function-declaration]\n",
      "  \u001b[31m   \u001b[0m  2507 |     PyObject* none = _PyList_Extend((PyListObject*)L, v);\n",
      "  \u001b[31m   \u001b[0m       |                      ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       |                      PyList_Extend\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:2507:22: error: initialization of ‘PyObject *’ {aka ‘struct _object *’} from ‘int’ makes pointer from integer without a cast [-Wint-conversion]\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__Pyx_init_assertions_enabled’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:2545:39: error: implicit declaration of function ‘_PyInterpreterState_GetConfig’; did you mean ‘PyInterpreterState_GetID’? [-Wimplicit-function-declaration]\n",
      "  \u001b[31m   \u001b[0m  2545 |     __pyx_assertions_enabled_flag = ! _PyInterpreterState_GetConfig(__Pyx_PyThreadState_Current->interp)->optimization_level;\n",
      "  \u001b[31m   \u001b[0m       |                                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       |                                       PyInterpreterState_GetID\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:2545:105: error: invalid type argument of ‘->’ (have ‘int’)\n",
      "  \u001b[31m   \u001b[0m  2545 |     __pyx_assertions_enabled_flag = ! _PyInterpreterState_GetConfig(__Pyx_PyThreadState_Current->interp)->optimization_level;\n",
      "  \u001b[31m   \u001b[0m       |                                                                                                         ^~\n",
      "  \u001b[31m   \u001b[0m In file included from /home/danilo/anaconda3/envs/mestrado/include/python3.13/Python.h:63,\n",
      "  \u001b[31m   \u001b[0m                  from econml/grf/_criterion.c:31:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__pyx_f_5numpy_PyDataType_SHAPE’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:11464:39: error: ‘PyArray_Descr’ {aka ‘struct _PyArray_Descr’} has no member named ‘subarray’\n",
      "  \u001b[31m   \u001b[0m 11464 |     __Pyx_INCREF(((PyObject*)__pyx_v_d->subarray->shape));\n",
      "  \u001b[31m   \u001b[0m       |                                       ^~\n",
      "  \u001b[31m   \u001b[0m /home/danilo/anaconda3/envs/mestrado/include/python3.13/pyport.h:19:38: note: in definition of macro ‘_Py_CAST’\n",
      "  \u001b[31m   \u001b[0m    19 | #define _Py_CAST(type, expr) ((type)(expr))\n",
      "  \u001b[31m   \u001b[0m       |                                      ^~~~\n",
      "  \u001b[31m   \u001b[0m /home/danilo/anaconda3/envs/mestrado/include/python3.13/object.h:846:35: note: in expansion of macro ‘_PyObject_CAST’\n",
      "  \u001b[31m   \u001b[0m   846 | #  define Py_INCREF(op) Py_INCREF(_PyObject_CAST(op))\n",
      "  \u001b[31m   \u001b[0m       |                                   ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:2101:27: note: in expansion of macro ‘Py_INCREF’\n",
      "  \u001b[31m   \u001b[0m  2101 |   #define __Pyx_INCREF(r) Py_INCREF(r)\n",
      "  \u001b[31m   \u001b[0m       |                           ^~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:11464:5: note: in expansion of macro ‘__Pyx_INCREF’\n",
      "  \u001b[31m   \u001b[0m 11464 |     __Pyx_INCREF(((PyObject*)__pyx_v_d->subarray->shape));\n",
      "  \u001b[31m   \u001b[0m       |     ^~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:11465:36: error: ‘PyArray_Descr’ {aka ‘struct _PyArray_Descr’} has no member named ‘subarray’\n",
      "  \u001b[31m   \u001b[0m 11465 |     __pyx_r = ((PyObject*)__pyx_v_d->subarray->shape);\n",
      "  \u001b[31m   \u001b[0m       |                                    ^~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__pyx_f_5numpy__util_dtypestring’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:11563:29: error: ‘PyArray_Descr’ {aka ‘struct _PyArray_Descr’} has no member named ‘names’\n",
      "  \u001b[31m   \u001b[0m 11563 |   if (unlikely(__pyx_v_descr->names == Py_None)) {\n",
      "  \u001b[31m   \u001b[0m       |                             ^~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:971:43: note: in definition of macro ‘unlikely’\n",
      "  \u001b[31m   \u001b[0m   971 |   #define unlikely(x) __builtin_expect(!!(x), 0)\n",
      "  \u001b[31m   \u001b[0m       |                                           ^\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:11567:28: error: ‘PyArray_Descr’ {aka ‘struct _PyArray_Descr’} has no member named ‘names’\n",
      "  \u001b[31m   \u001b[0m 11567 |   __pyx_t_1 = __pyx_v_descr->names; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;\n",
      "  \u001b[31m   \u001b[0m       |                            ^~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:11586:31: error: ‘PyArray_Descr’ {aka ‘struct _PyArray_Descr’} has no member named ‘fields’\n",
      "  \u001b[31m   \u001b[0m 11586 |     if (unlikely(__pyx_v_descr->fields == Py_None)) {\n",
      "  \u001b[31m   \u001b[0m       |                               ^~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:971:43: note: in definition of macro ‘unlikely’\n",
      "  \u001b[31m   \u001b[0m   971 |   #define unlikely(x) __builtin_expect(!!(x), 0)\n",
      "  \u001b[31m   \u001b[0m       |                                           ^\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:11590:51: error: ‘PyArray_Descr’ {aka ‘struct _PyArray_Descr’} has no member named ‘fields’\n",
      "  \u001b[31m   \u001b[0m 11590 |     __pyx_t_3 = __Pyx_PyDict_GetItem(__pyx_v_descr->fields, __pyx_v_childname); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 851, __pyx_L1_error)\n",
      "  \u001b[31m   \u001b[0m       |                                                   ^~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:11791:79: error: ‘PyArray_Descr’ {aka ‘struct _PyArray_Descr’} has no member named ‘elsize’\n",
      "  \u001b[31m   \u001b[0m 11791 |     (__pyx_v_offset[__pyx_t_8]) = ((__pyx_v_offset[__pyx_t_8]) + __pyx_v_child->elsize);\n",
      "  \u001b[31m   \u001b[0m       |                                                                               ^~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__Pyx_PyInt_As_Py_intptr_t’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:30992:27: error: too few arguments to function ‘_PyLong_AsByteArray’\n",
      "  \u001b[31m   \u001b[0m 30992 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n",
      "  \u001b[31m   \u001b[0m       |                           ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m In file included from /home/danilo/anaconda3/envs/mestrado/include/python3.13/longobject.h:107,\n",
      "  \u001b[31m   \u001b[0m                  from /home/danilo/anaconda3/envs/mestrado/include/python3.13/Python.h:81:\n",
      "  \u001b[31m   \u001b[0m /home/danilo/anaconda3/envs/mestrado/include/python3.13/cpython/longobject.h:111:17: note: declared here\n",
      "  \u001b[31m   \u001b[0m   111 | PyAPI_FUNC(int) _PyLong_AsByteArray(PyLongObject* v,\n",
      "  \u001b[31m   \u001b[0m       |                 ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__Pyx_PyInt_As_npy_uint32’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:31188:27: error: too few arguments to function ‘_PyLong_AsByteArray’\n",
      "  \u001b[31m   \u001b[0m 31188 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n",
      "  \u001b[31m   \u001b[0m       |                           ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m /home/danilo/anaconda3/envs/mestrado/include/python3.13/cpython/longobject.h:111:17: note: declared here\n",
      "  \u001b[31m   \u001b[0m   111 | PyAPI_FUNC(int) _PyLong_AsByteArray(PyLongObject* v,\n",
      "  \u001b[31m   \u001b[0m       |                 ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__Pyx_PyInt_As_int’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:31460:27: error: too few arguments to function ‘_PyLong_AsByteArray’\n",
      "  \u001b[31m   \u001b[0m 31460 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n",
      "  \u001b[31m   \u001b[0m       |                           ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m /home/danilo/anaconda3/envs/mestrado/include/python3.13/cpython/longobject.h:111:17: note: declared here\n",
      "  \u001b[31m   \u001b[0m   111 | PyAPI_FUNC(int) _PyLong_AsByteArray(PyLongObject* v,\n",
      "  \u001b[31m   \u001b[0m       |                 ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__Pyx_PyInt_As_long’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:31732:27: error: too few arguments to function ‘_PyLong_AsByteArray’\n",
      "  \u001b[31m   \u001b[0m 31732 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n",
      "  \u001b[31m   \u001b[0m       |                           ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m /home/danilo/anaconda3/envs/mestrado/include/python3.13/cpython/longobject.h:111:17: note: declared here\n",
      "  \u001b[31m   \u001b[0m   111 | PyAPI_FUNC(int) _PyLong_AsByteArray(PyLongObject* v,\n",
      "  \u001b[31m   \u001b[0m       |                 ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c: In function ‘__Pyx_PyInt_As_char’:\n",
      "  \u001b[31m   \u001b[0m econml/grf/_criterion.c:31928:27: error: too few arguments to function ‘_PyLong_AsByteArray’\n",
      "  \u001b[31m   \u001b[0m 31928 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n",
      "  \u001b[31m   \u001b[0m       |                           ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m /home/danilo/anaconda3/envs/mestrado/include/python3.13/cpython/longobject.h:111:17: note: declared here\n",
      "  \u001b[31m   \u001b[0m   111 | PyAPI_FUNC(int) _PyLong_AsByteArray(PyLongObject* v,\n",
      "  \u001b[31m   \u001b[0m       |                 ^~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for econml\u001b[0m\u001b[31m\n",
      "\u001b[0m  Building wheel for numpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-linux_x86_64.whl size=9188161 sha256=66ece8b28c7ca2f6132b5047f8d0d4041fdf8f088fa64a96090b2f6985e9ed19\n",
      "  Stored in directory: /home/danilo/.var/app/com.visualstudio.code/cache/pip/wheels/8b/2d/9f/b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "  Building wheel for shap (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.43.0-cp313-cp313-linux_x86_64.whl size=447467 sha256=cf98a741d89dc5761e45dac043a706e93cac800ca1086ef2cf20c86afea2fb91\n",
      "  Stored in directory: /home/danilo/.var/app/com.visualstudio.code/cache/pip/wheels/7e/24/1f/8009113a90d2a8f0ac59016ea30907f67d4942a850259022e5\n",
      "  Building wheel for cons (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cons: filename=cons-0.4.6-py3-none-any.whl size=9157 sha256=8b9c27d64c92e3d580bfd2e63ccb60dd587971e8d420dc689fdc5ee0bbfe0ace\n",
      "  Stored in directory: /home/danilo/.var/app/com.visualstudio.code/cache/pip/wheels/9e/f3/ac/a1bb27e2d5f61ef0ecd7012c4af79a63e570227924558c9d8c\n",
      "  Building wheel for etuples (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for etuples: filename=etuples-0.3.9-py3-none-any.whl size=12673 sha256=189243636f428f10f80432b42100a23ee41b5760d02a3b12d03958853b9d2e0e\n",
      "  Stored in directory: /home/danilo/.var/app/com.visualstudio.code/cache/pip/wheels/21/4a/27/f6311ea84f7328a594031e424df18f39865352b1797dce836f\n",
      "  Building wheel for logical-unification (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for logical-unification: filename=logical_unification-0.4.6-py3-none-any.whl size=13972 sha256=5f69a21bc6fbd5bf01c162c96dbe2f6d874c0d897bd6bb330e5a93254f28f005\n",
      "  Stored in directory: /home/danilo/.var/app/com.visualstudio.code/cache/pip/wheels/50/9a/bf/3927d356d65af78752ad339a5a29142ecc58c19d5c57531ede\n",
      "Successfully built numpy shap cons etuples logical-unification\n",
      "Failed to build econml\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (econml)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r /home/danilo/repos/statistical_agent_medical_data/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c81ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para inferência causal, instale: pip install dowhy econml\n",
      "Para programação probabilística, instale: pip install pymc arviz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statistical_agent import StatisticalAgent\n",
    "from datasets import DatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b32e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset epidemiológico sintético criado com sucesso!\n",
      "📊 Dimensões: (2000, 17)\n",
      "🎯 Variável alvo: 'cardiovascular_event'\n",
      "📈 Prevalência de eventos cardiovasculares: 97.35%\n",
      "📈 Prevalência de diabetes: 74.12%\n",
      "📈 Prevalência de hipertensão: 73.97%\n",
      "💊 Taxa de tratamento: 42.37%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Carregar dataset\n",
    "loader = DatasetLoader()\n",
    "data = loader.create_synthetic_epidemiological_data()\n",
    "\n",
    "# Usar agente\n",
    "#agent = StatisticalAgent()\n",
    "#results = agent.run_analysis(data, \"Sua solicitação aqui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "886d77f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>education_years</th>\n",
       "      <th>income_level</th>\n",
       "      <th>smoking</th>\n",
       "      <th>alcohol_consumption</th>\n",
       "      <th>exercise_hours_week</th>\n",
       "      <th>bmi</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>treatment</th>\n",
       "      <th>cardiovascular_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>38.4</td>\n",
       "      <td>205.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>207.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>22.7</td>\n",
       "      <td>216.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id   age  sex  education_years  income_level  smoking  \\\n",
       "0           1  64.0  1.0             18.0           2.0      NaN   \n",
       "1           2  53.0  1.0             11.0           1.0      1.0   \n",
       "2           3  67.0  1.0             14.0           2.0      0.0   \n",
       "3           4  82.0  1.0             14.0           3.0      0.0   \n",
       "4           5   NaN  0.0             17.0           5.0      0.0   \n",
       "\n",
       "   alcohol_consumption  exercise_hours_week   bmi  systolic_bp  diastolic_bp  \\\n",
       "0                  0.2                  4.9  38.4        205.0         112.0   \n",
       "1                  0.7                  2.2  24.7        207.0         117.0   \n",
       "2                  7.2                  5.7  28.0        186.0         125.0   \n",
       "3                  1.6                  0.6  22.7        216.0         135.0   \n",
       "4                  0.9                  5.6  24.1        171.0         102.0   \n",
       "\n",
       "   cholesterol  glucose  diabetes  hypertension  treatment  \\\n",
       "0        253.0    142.0       1.0           1.0        0.0   \n",
       "1        291.0    124.0       1.0           1.0        1.0   \n",
       "2        279.0    134.0       1.0           1.0        0.0   \n",
       "3        241.0    127.0       0.0           1.0        0.0   \n",
       "4        238.0    133.0       1.0           1.0        0.0   \n",
       "\n",
       "   cardiovascular_event  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f772265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Defina sua chave de API do OpenAI aqui\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac88f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar agente\n",
    "agent = StatisticalAgent()\n",
    "results = agent.run_analysis(data, \"Sua solicitação aqui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4784ae0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': StatisticalResult(analysis_type=<AnalysisType.DESCRIPTIVE: 'descriptive'>, results={'summary_stats': {'patient_id': {'count': 2000.0, 'mean': 1000.5, 'std': 577.4945887192364, 'min': 1.0, '25%': 500.75, '50%': 1000.5, '75%': 1500.25, 'max': 2000.0}, 'age': {'count': 1965.0, 'mean': 55.796946564885495, 'std': 17.29971188791837, 'min': 18.0, '25%': 44.0, '50%': 56.0, '75%': 67.0, 'max': 95.0}, 'sex': {'count': 1965.0, 'mean': 0.5297709923664122, 'std': 0.4992399503013233, 'min': 0.0, '25%': 0.0, '50%': 1.0, '75%': 1.0, 'max': 1.0}, 'education_years': {'count': 1967.0, 'mean': 11.976105744789018, 'std': 3.4219889876710963, 'min': 3.0, '25%': 10.0, '50%': 12.0, '75%': 14.0, 'max': 24.0}, 'income_level': {'count': 1967.0, 'mean': 2.7320793085917643, 'std': 1.2278155087445595, 'min': 1.0, '25%': 2.0, '50%': 3.0, '75%': 4.0, 'max': 5.0}, 'smoking': {'count': 1963.0, 'mean': 0.20988283239938868, 'std': 0.40732855411157143, 'min': 0.0, '25%': 0.0, '50%': 0.0, '75%': 0.0, 'max': 1.0}, 'alcohol_consumption': {'count': 1964.0, 'mean': 2.029735234215886, 'std': 2.04468714559043, 'min': 0.0, '25%': 0.6, '50%': 1.4, '75%': 2.9, 'max': 19.0}, 'exercise_hours_week': {'count': 1973.0, 'mean': 4.068727825646224, 'std': 2.821171094104743, 'min': 0.0, '25%': 2.0, '50%': 3.4, '75%': 5.5, 'max': 19.0}, 'bmi': {'count': 1956.0, 'mean': 26.242229038854806, 'std': 4.918587943323772, 'min': 15.0, '25%': 22.9, '50%': 26.2, '75%': 29.7, 'max': 43.8}, 'systolic_bp': {'count': 1955.0, 'mean': 190.55601023017903, 'std': 18.315619915703564, 'min': 128.0, '25%': 178.0, '50%': 190.0, '75%': 203.0, 'max': 253.0}, 'diastolic_bp': {'count': 1952.0, 'mean': 118.0952868852459, 'std': 11.866856546054903, 'min': 79.0, '25%': 110.0, '50%': 118.0, '75%': 126.0, 'max': 167.0}, 'cholesterol': {'count': 1958.0, 'mean': 247.24668028600613, 'std': 32.56548650494821, 'min': 129.0, '25%': 225.0, '50%': 247.0, '75%': 268.0, 'max': 353.0}, 'glucose': {'count': 1957.0, 'mean': 122.35820132856414, 'std': 15.865905054058365, 'min': 69.0, '25%': 111.0, '50%': 123.0, '75%': 133.0, 'max': 176.0}, 'diabetes': {'count': 1959.0, 'mean': 0.7411944869831547, 'std': 0.4380903895638676, 'min': 0.0, '25%': 0.0, '50%': 1.0, '75%': 1.0, 'max': 1.0}, 'hypertension': {'count': 1959.0, 'mean': 0.7396630934150077, 'std': 0.43893045886907134, 'min': 0.0, '25%': 0.0, '50%': 1.0, '75%': 1.0, 'max': 1.0}, 'treatment': {'count': 1966.0, 'mean': 0.4237029501525941, 'std': 0.4942701935021735, 'min': 0.0, '25%': 0.0, '50%': 0.0, '75%': 1.0, 'max': 1.0}, 'cardiovascular_event': {'count': 2000.0, 'mean': 0.9735, 'std': 0.1606569492044008, 'min': 0.0, '25%': 1.0, '50%': 1.0, '75%': 1.0, 'max': 1.0}}, 'correlations': {'patient_id': {'patient_id': 1.0, 'age': 0.030433592052848207, 'sex': -0.00329863289813222, 'education_years': 0.006031499130055571, 'income_level': 0.01029732742525478, 'smoking': -0.02939789808987735, 'alcohol_consumption': -0.024930082864044512, 'exercise_hours_week': 0.0007480537367521538, 'bmi': 0.022253042417689703, 'systolic_bp': 0.036150218460817195, 'diastolic_bp': 0.018081271159932345, 'cholesterol': 0.01892391303841384, 'glucose': 0.016385592371393268, 'diabetes': 0.047747712315485275, 'hypertension': 0.012112940472190395, 'treatment': -2.473698850134008e-05, 'cardiovascular_event': 0.053047956776889976}, 'age': {'patient_id': 0.030433592052848207, 'age': 1.0, 'sex': -0.04133743870408002, 'education_years': -0.04165506868890871, 'income_level': 0.06775136426660451, 'smoking': 0.005422763648572291, 'alcohol_consumption': -0.014822693333487026, 'exercise_hours_week': -0.03306937031395428, 'bmi': 0.01861619331753187, 'systolic_bp': 0.2765670299160046, 'diastolic_bp': 0.3052788304670229, 'cholesterol': 0.3206941518956744, 'glucose': 0.23000418039787038, 'diabetes': 0.3379538159338136, 'hypertension': 0.2877003907591404, 'treatment': 0.22438212673066266, 'cardiovascular_event': 0.22226608597109476}, 'sex': {'patient_id': -0.00329863289813222, 'age': -0.04133743870408002, 'sex': 1.0, 'education_years': -0.006823928882848809, 'income_level': -0.03258724272886278, 'smoking': 0.13150171800013735, 'alcohol_consumption': 0.009338963490051571, 'exercise_hours_week': 0.019947004594477503, 'bmi': 0.0076055842696026825, 'systolic_bp': -0.010623222699969202, 'diastolic_bp': -0.0023792314157505736, 'cholesterol': -0.03832677214806097, 'glucose': 0.028951315925300838, 'diabetes': -0.013746225283237446, 'hypertension': -0.034422877532043296, 'treatment': -0.016500541602354465, 'cardiovascular_event': -0.02828057707657424}, 'education_years': {'patient_id': 0.006031499130055571, 'age': -0.04165506868890871, 'sex': -0.006823928882848809, 'education_years': 1.0, 'income_level': -0.011002204961095363, 'smoking': 0.016453198885907114, 'alcohol_consumption': -0.01899292959199089, 'exercise_hours_week': 0.0008613571956595208, 'bmi': 0.029395406566529857, 'systolic_bp': 0.01645137638686486, 'diastolic_bp': -0.022833166571821238, 'cholesterol': 0.002571205999631631, 'glucose': -0.02599415379491713, 'diabetes': -0.011007138404853335, 'hypertension': -0.006463404540723367, 'treatment': -0.0021834404390856745, 'cardiovascular_event': -0.0029977242847211384}, 'income_level': {'patient_id': 0.01029732742525478, 'age': 0.06775136426660451, 'sex': -0.03258724272886278, 'education_years': -0.011002204961095363, 'income_level': 1.0, 'smoking': -0.016749718708871607, 'alcohol_consumption': -0.006718097460820402, 'exercise_hours_week': 0.014212188704821565, 'bmi': -0.032217545058415245, 'systolic_bp': -0.0319642543957663, 'diastolic_bp': 0.031862128648446696, 'cholesterol': 0.019354393190311816, 'glucose': 0.01282129779093566, 'diabetes': -0.0639580989374911, 'hypertension': 0.016855224388316967, 'treatment': 0.07973436187873226, 'cardiovascular_event': 0.01651249515399325}, 'smoking': {'patient_id': -0.02939789808987735, 'age': 0.005422763648572291, 'sex': 0.13150171800013735, 'education_years': 0.016453198885907114, 'income_level': -0.016749718708871607, 'smoking': 1.0, 'alcohol_consumption': 0.014105734559973056, 'exercise_hours_week': -0.01964948237554094, 'bmi': 0.020652366540690793, 'systolic_bp': 0.11459611540027495, 'diastolic_bp': 0.1090540958756092, 'cholesterol': 0.024871151768945682, 'glucose': 0.008086220182598556, 'diabetes': 0.01564793415386845, 'hypertension': 0.06485079766832827, 'treatment': -0.005014495029135167, 'cardiovascular_event': 0.05271962960304015}, 'alcohol_consumption': {'patient_id': -0.024930082864044512, 'age': -0.014822693333487026, 'sex': 0.009338963490051571, 'education_years': -0.01899292959199089, 'income_level': -0.006718097460820402, 'smoking': 0.014105734559973056, 'alcohol_consumption': 1.0, 'exercise_hours_week': 0.025271516626596182, 'bmi': -0.01203526558712107, 'systolic_bp': 0.004753586431287612, 'diastolic_bp': -0.015974978152840574, 'cholesterol': -0.0069920516067740815, 'glucose': 0.020067910159262754, 'diabetes': -0.011362559628586571, 'hypertension': 0.009467522525263871, 'treatment': 0.014585088265858899, 'cardiovascular_event': 0.024429510235240582}, 'exercise_hours_week': {'patient_id': 0.0007480537367521538, 'age': -0.03306937031395428, 'sex': 0.019947004594477503, 'education_years': 0.0008613571956595208, 'income_level': 0.014212188704821565, 'smoking': -0.01964948237554094, 'alcohol_consumption': 0.025271516626596182, 'exercise_hours_week': 1.0, 'bmi': -0.005691934338732155, 'systolic_bp': -0.05198242215132775, 'diastolic_bp': -0.007264569882463604, 'cholesterol': -0.002647440170701177, 'glucose': -0.03102504949928853, 'diabetes': -0.07663438181159012, 'hypertension': -0.03259369630146904, 'treatment': -0.024646900292053523, 'cardiovascular_event': -0.04763412467464415}, 'bmi': {'patient_id': 0.022253042417689703, 'age': 0.01861619331753187, 'sex': 0.0076055842696026825, 'education_years': 0.029395406566529857, 'income_level': -0.032217545058415245, 'smoking': 0.020652366540690793, 'alcohol_consumption': -0.01203526558712107, 'exercise_hours_week': -0.005691934338732155, 'bmi': 1.0, 'systolic_bp': 0.5052289183103087, 'diastolic_bp': 0.4237068621785932, 'cholesterol': 0.2308444279114468, 'glucose': 0.2321392219006171, 'diabetes': 0.27889768899324896, 'hypertension': 0.2748530998674919, 'treatment': 0.035200873102587536, 'cardiovascular_event': 0.14608686496187695}, 'systolic_bp': {'patient_id': 0.036150218460817195, 'age': 0.2765670299160046, 'sex': -0.010623222699969202, 'education_years': 0.01645137638686486, 'income_level': -0.0319642543957663, 'smoking': 0.11459611540027495, 'alcohol_consumption': 0.004753586431287612, 'exercise_hours_week': -0.05198242215132775, 'bmi': 0.5052289183103087, 'systolic_bp': 1.0, 'diastolic_bp': 0.3057530769170827, 'cholesterol': 0.200234525450747, 'glucose': 0.16311092194374738, 'diabetes': 0.229899607342668, 'hypertension': 0.272616105545412, 'treatment': 0.08977672007392196, 'cardiovascular_event': 0.14216933433209022}, 'diastolic_bp': {'patient_id': 0.018081271159932345, 'age': 0.3052788304670229, 'sex': -0.0023792314157505736, 'education_years': -0.022833166571821238, 'income_level': 0.031862128648446696, 'smoking': 0.1090540958756092, 'alcohol_consumption': -0.015974978152840574, 'exercise_hours_week': -0.007264569882463604, 'bmi': 0.4237068621785932, 'systolic_bp': 0.3057530769170827, 'diastolic_bp': 1.0, 'cholesterol': 0.22574381879127994, 'glucose': 0.17944823336792812, 'diabetes': 0.21357340603305713, 'hypertension': 0.15668771005035106, 'treatment': 0.06828518843141446, 'cardiovascular_event': 0.09877004414169693}, 'cholesterol': {'patient_id': 0.01892391303841384, 'age': 0.3206941518956744, 'sex': -0.03832677214806097, 'education_years': 0.002571205999631631, 'income_level': 0.019354393190311816, 'smoking': 0.024871151768945682, 'alcohol_consumption': -0.0069920516067740815, 'exercise_hours_week': -0.002647440170701177, 'bmi': 0.2308444279114468, 'systolic_bp': 0.200234525450747, 'diastolic_bp': 0.22574381879127994, 'cholesterol': 1.0, 'glucose': 0.13858395142111865, 'diabetes': 0.18871517503771829, 'hypertension': 0.1635261431175336, 'treatment': 0.11181296295042713, 'cardiovascular_event': 0.11052333358813392}, 'glucose': {'patient_id': 0.016385592371393268, 'age': 0.23000418039787038, 'sex': 0.028951315925300838, 'education_years': -0.02599415379491713, 'income_level': 0.01282129779093566, 'smoking': 0.008086220182598556, 'alcohol_consumption': 0.020067910159262754, 'exercise_hours_week': -0.03102504949928853, 'bmi': 0.2321392219006171, 'systolic_bp': 0.16311092194374738, 'diastolic_bp': 0.17944823336792812, 'cholesterol': 0.13858395142111865, 'glucose': 1.0, 'diabetes': 0.21651217782331234, 'hypertension': 0.11140219997910435, 'treatment': 0.04064861021502757, 'cardiovascular_event': 0.09327353197804691}, 'diabetes': {'patient_id': 0.047747712315485275, 'age': 0.3379538159338136, 'sex': -0.013746225283237446, 'education_years': -0.011007138404853335, 'income_level': -0.0639580989374911, 'smoking': 0.01564793415386845, 'alcohol_consumption': -0.011362559628586571, 'exercise_hours_week': -0.07663438181159012, 'bmi': 0.27889768899324896, 'systolic_bp': 0.229899607342668, 'diastolic_bp': 0.21357340603305713, 'cholesterol': 0.18871517503771829, 'glucose': 0.21651217782331234, 'diabetes': 1.0, 'hypertension': 0.17495761294725887, 'treatment': 0.1263084350217067, 'cardiovascular_event': 0.18884611180951116}, 'hypertension': {'patient_id': 0.012112940472190395, 'age': 0.2877003907591404, 'sex': -0.034422877532043296, 'education_years': -0.006463404540723367, 'income_level': 0.016855224388316967, 'smoking': 0.06485079766832827, 'alcohol_consumption': 0.009467522525263871, 'exercise_hours_week': -0.03259369630146904, 'bmi': 0.2748530998674919, 'systolic_bp': 0.272616105545412, 'diastolic_bp': 0.15668771005035106, 'cholesterol': 0.1635261431175336, 'glucose': 0.11140219997910435, 'diabetes': 0.17495761294725887, 'hypertension': 1.0, 'treatment': 0.14183340295588176, 'cardiovascular_event': 0.22768326006300868}, 'treatment': {'patient_id': -2.473698850134008e-05, 'age': 0.22438212673066266, 'sex': -0.016500541602354465, 'education_years': -0.0021834404390856745, 'income_level': 0.07973436187873226, 'smoking': -0.005014495029135167, 'alcohol_consumption': 0.014585088265858899, 'exercise_hours_week': -0.024646900292053523, 'bmi': 0.035200873102587536, 'systolic_bp': 0.08977672007392196, 'diastolic_bp': 0.06828518843141446, 'cholesterol': 0.11181296295042713, 'glucose': 0.04064861021502757, 'diabetes': 0.1263084350217067, 'hypertension': 0.14183340295588176, 'treatment': 1.0, 'cardiovascular_event': 0.05152607260627961}, 'cardiovascular_event': {'patient_id': 0.053047956776889976, 'age': 0.22226608597109476, 'sex': -0.02828057707657424, 'education_years': -0.0029977242847211384, 'income_level': 0.01651249515399325, 'smoking': 0.05271962960304015, 'alcohol_consumption': 0.024429510235240582, 'exercise_hours_week': -0.04763412467464415, 'bmi': 0.14608686496187695, 'systolic_bp': 0.14216933433209022, 'diastolic_bp': 0.09877004414169693, 'cholesterol': 0.11052333358813392, 'glucose': 0.09327353197804691, 'diabetes': 0.18884611180951116, 'hypertension': 0.22768326006300868, 'treatment': 0.05152607260627961, 'cardiovascular_event': 1.0}}, 'distribution_tests': {'patient_id': {'shapiro_stat': 0.9548662613608034, 'shapiro_p': 2.145811356042863e-24, 'is_normal': np.False_}, 'age': {'shapiro_stat': 0.9928187280026843, 'shapiro_p': 3.2486566367533306e-08, 'is_normal': np.False_}, 'sex': {'shapiro_stat': 0.6353236311452757, 'shapiro_p': 9.728438638449576e-54, 'is_normal': np.False_}, 'education_years': {'shapiro_stat': 0.9850269912903211, 'shapiro_p': 1.7314547090693381e-13, 'is_normal': np.False_}, 'income_level': {'shapiro_stat': 0.9075522307400339, 'shapiro_p': 5.716073283575761e-33, 'is_normal': np.False_}, 'smoking': {'shapiro_stat': 0.5004936511095729, 'shapiro_p': 3.1847445927800404e-59, 'is_normal': np.False_}, 'alcohol_consumption': {'shapiro_stat': 0.8103210871401948, 'shapiro_p': 3.564275173215249e-43, 'is_normal': np.False_}, 'exercise_hours_week': {'shapiro_stat': 0.9041626335333008, 'shapiro_p': 1.7170716392664126e-33, 'is_normal': np.False_}, 'bmi': {'shapiro_stat': 0.9971223375816882, 'shapiro_p': 0.001075157652513648, 'is_normal': np.False_}, 'systolic_bp': {'shapiro_stat': 0.9993496492370996, 'shapiro_p': 0.7619484976468686, 'is_normal': np.True_}, 'diastolic_bp': {'shapiro_stat': 0.9982012221052182, 'shapiro_p': 0.030776348582125683, 'is_normal': np.False_}, 'cholesterol': {'shapiro_stat': 0.9981594760854352, 'shapiro_p': 0.026487327980313072, 'is_normal': np.False_}, 'glucose': {'shapiro_stat': 0.9987056810498683, 'shapiro_p': 0.14939064097953486, 'is_normal': np.True_}, 'diabetes': {'shapiro_stat': 0.5458454904521126, 'shapiro_p': 1.7327392007369493e-57, 'is_normal': np.False_}, 'hypertension': {'shapiro_stat': 0.5470814477942456, 'shapiro_p': 1.9357796724242124e-57, 'is_normal': np.False_}, 'treatment': {'shapiro_stat': 0.6280939026251862, 'shapiro_p': 4.392557090296831e-54, 'is_normal': np.False_}, 'cardiovascular_event': {'shapiro_stat': 0.1459243964682948, 'shapiro_p': 1.1395938402047424e-69, 'is_normal': np.False_}}, 'clinical_insights': []}, interpretation='1. Interpretação clínica clara:\\n\\nOs dados analisados são de 2000 pacientes, com idades variando de 18 a 95 anos, sendo a média de idade aproximadamente 56 anos. Aproximadamente 53% dos pacientes são do sexo masculino (assumindo que 1 representa masculino e 0 feminino). A média de anos de educação é de aproximadamente 12 anos, com um mínimo de 3 e um máximo de 24 anos. O nível de renda varia de 1 a 5, com uma média de aproximadamente 2.73. Cerca de 21% dos pacientes são fumantes e a média de consumo de álcool é de aproximadamente 2.03. Os pacientes exercitam-se em média 4 horas por semana, com um mínimo de 0 e um máximo de 19 horas. A média do índice de massa corporal (IMC) é de aproximadamente 26.24, com um mínimo de 15 e um máximo de 43.8. A pressão arterial sistólica média é de aproximadamente 190.56 e a diastólica é de aproximadamente 118.10. A média de colesterol é de aproximadamente 247.25 e a de glicose é de aproximadamente 122.36. Cerca de 74% dos pacientes têm diabetes e hipertensão. Cerca de 42% dos pacientes estão em tratamento e 97% tiveram um evento cardiovascular.\\n\\n2. Limitações e considerações:\\n\\nOs dados apresentam algumas limitações. Primeiro, há uma falta de normalidade em muitas das variáveis, como indicado pelos testes de Shapiro-Wilk. Isso pode afetar a validade de alguns testes estatísticos que assumem a normalidade dos dados. Além disso, há uma falta de explicabilidade fornecida para os resultados, o que pode dificultar a interpretação dos resultados. Além disso, algumas variáveis têm contagens menores que 2000, indicando que há dados faltantes nessas variáveis.\\n\\n3. Recomendações práticas:\\n\\nCom base nos resultados, recomenda-se que os profissionais de saúde se concentrem em intervenções direcionadas a fatores de risco modificáveis, como tabagismo, consumo de álcool, falta de exercício e controle do IMC. Além disso, os profissionais de saúde devem estar cientes de que a maioria dos pacientes nesta amostra teve um evento cardiovascular, o que indica a necessidade de monitoramento e tratamento contínuos. Além disso, é importante considerar a realização de mais pesquisas para entender melhor os fatores que contribuem para o alto índice de eventos cardiovasculares nesta população.', confidence=0.95, recommendations=[], explainability={}),\n",
       " 'models': {},\n",
       " 'messages': ['Sua solicitação aqui',\n",
       "  '\\n## Análise Estatística Concluída\\n\\n**Tipo de Análise:** Descriptive\\n\\n**Interpretação:**\\n1. Interpretação clínica clara:\\n\\nOs dados analisados são de 2000 pacientes, com idades variando de 18 a 95 anos, sendo a média de idade aproximadamente 56 anos. Aproximadamente 53% dos pacientes são do sexo masculino (assumindo que 1 representa masculino e 0 feminino). A média de anos de educação é de aproximadamente 12 anos, com um mínimo de 3 e um máximo de 24 anos. O nível de renda varia de 1 a 5, com uma média de aproximadamente 2.73. Cerca de 21% dos pacientes são fumantes e a média de consumo de álcool é de aproximadamente 2.03. Os pacientes exercitam-se em média 4 horas por semana, com um mínimo de 0 e um máximo de 19 horas. A média do índice de massa corporal (IMC) é de aproximadamente 26.24, com um mínimo de 15 e um máximo de 43.8. A pressão arterial sistólica média é de aproximadamente 190.56 e a diastólica é de aproximadamente 118.10. A média de colesterol é de aproximadamente 247.25 e a de glicose é de aproximadamente 122.36. Cerca de 74% dos pacientes têm diabetes e hipertensão. Cerca de 42% dos pacientes estão em tratamento e 97% tiveram um evento cardiovascular.\\n\\n2. Limitações e considerações:\\n\\nOs dados apresentam algumas limitações. Primeiro, há uma falta de normalidade em muitas das variáveis, como indicado pelos testes de Shapiro-Wilk. Isso pode afetar a validade de alguns testes estatísticos que assumem a normalidade dos dados. Além disso, há uma falta de explicabilidade fornecida para os resultados, o que pode dificultar a interpretação dos resultados. Além disso, algumas variáveis têm contagens menores que 2000, indicando que há dados faltantes nessas variáveis.\\n\\n3. Recomendações práticas:\\n\\nCom base nos resultados, recomenda-se que os profissionais de saúde se concentrem em intervenções direcionadas a fatores de risco modificáveis, como tabagismo, consumo de álcool, falta de exercício e controle do IMC. Além disso, os profissionais de saúde devem estar cientes de que a maioria dos pacientes nesta amostra teve um evento cardiovascular, o que indica a necessidade de monitoramento e tratamento contínuos. Além disso, é importante considerar a realização de mais pesquisas para entender melhor os fatores que contribuem para o alto índice de eventos cardiovasculares nesta população.\\n\\n**Confiança:** 95.00%\\n\\n**Recomendações:**\\n\\n\\n**Transparência e Explicabilidade:**\\nEsta análise utilizou técnicas de XAI para garantir interpretabilidade dos resultados.\\n            ']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9256fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dowhy\n",
      "  Using cached dowhy-0.8-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from dowhy) (2.2.3)\n",
      "Requirement already satisfied: scipy in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from dowhy) (1.15.2)\n",
      "Collecting statsmodels (from dowhy)\n",
      "  Using cached statsmodels-0.14.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from dowhy) (2.2.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from dowhy) (3.4.2)\n",
      "Requirement already satisfied: sympy>=1.4 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from dowhy) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from dowhy) (1.6.1)\n",
      "Collecting pydot>=1.4 (from dowhy)\n",
      "  Using cached pydot-4.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=0.24->dowhy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=0.24->dowhy) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=0.24->dowhy) (2025.1)\n",
      "Requirement already satisfied: pyparsing>=3.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pydot>=1.4->dowhy) (3.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from sympy>=1.4->dowhy) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from scikit-learn->dowhy) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from scikit-learn->dowhy) (3.6.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels->dowhy)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from statsmodels->dowhy) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=0.24->dowhy) (1.17.0)\n",
      "Using cached dowhy-0.8-py3-none-any.whl (287 kB)\n",
      "Using cached pydot-4.0.1-py3-none-any.whl (37 kB)\n",
      "Using cached statsmodels-0.14.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: pydot, patsy, statsmodels, dowhy\n",
      "Successfully installed dowhy-0.8 patsy-1.0.1 pydot-4.0.1 statsmodels-0.14.4\n",
      "Collecting pymc\n",
      "  Using cached pymc-5.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting arviz>=0.13.0 (from pymc)\n",
      "  Using cached arviz-0.21.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: cachetools>=4.2.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc) (5.5.2)\n",
      "Requirement already satisfied: cloudpickle in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc) (2.2.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc) (2.2.3)\n",
      "Collecting pytensor<2.32,>=2.31.2 (from pymc)\n",
      "  Downloading pytensor-2.31.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: rich>=13.7.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc) (13.9.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl<4.0.0,>=3.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pymc) (4.14.0)\n",
      "Requirement already satisfied: setuptools>=60.0.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz>=0.13.0->pymc) (75.8.2)\n",
      "Requirement already satisfied: matplotlib>=3.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz>=0.13.0->pymc) (3.10.0)\n",
      "Requirement already satisfied: packaging in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz>=0.13.0->pymc) (24.2)\n",
      "Collecting xarray>=2022.6.0 (from arviz>=0.13.0->pymc)\n",
      "  Downloading xarray-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting h5netcdf>=1.0.2 (from arviz>=0.13.0->pymc)\n",
      "  Downloading h5netcdf-1.6.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting xarray-einstats>=0.3 (from arviz>=0.13.0->pymc)\n",
      "  Using cached xarray_einstats-0.9.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=0.24.0->pymc) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=0.24.0->pymc) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=0.24.0->pymc) (2025.1)\n",
      "Requirement already satisfied: filelock>=3.15 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pytensor<2.32,>=2.31.2->pymc) (3.17.0)\n",
      "Collecting etuples (from pytensor<2.32,>=2.31.2->pymc)\n",
      "  Using cached etuples-0.3.9-py3-none-any.whl\n",
      "Collecting logical-unification (from pytensor<2.32,>=2.31.2->pymc)\n",
      "  Using cached logical_unification-0.4.6-py3-none-any.whl\n",
      "Collecting miniKanren (from pytensor<2.32,>=2.31.2->pymc)\n",
      "  Using cached minikanren-1.0.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting cons (from pytensor<2.32,>=2.31.2->pymc)\n",
      "  Using cached cons-0.4.6-py3-none-any.whl\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from rich>=13.7.1->pymc) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from rich>=13.7.1->pymc) (2.19.1)\n",
      "Collecting h5py (from h5netcdf>=1.0.2->arviz>=0.13.0->pymc)\n",
      "  Using cached h5py-3.14.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->pymc) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (3.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->pymc) (1.17.0)\n",
      "Collecting toolz (from logical-unification->pytensor<2.32,>=2.31.2->pymc)\n",
      "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting multipledispatch (from logical-unification->pytensor<2.32,>=2.31.2->pymc)\n",
      "  Using cached multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Using cached pymc-5.23.0-py3-none-any.whl (519 kB)\n",
      "Using cached arviz-0.21.0-py3-none-any.whl (1.7 MB)\n",
      "Downloading pytensor-2.31.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5netcdf-1.6.3-py3-none-any.whl (50 kB)\n",
      "Downloading xarray-2025.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached xarray_einstats-0.9.1-py3-none-any.whl (39 kB)\n",
      "Using cached minikanren-1.0.5-py3-none-any.whl (24 kB)\n",
      "Using cached h5py-3.14.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "Using cached multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: multipledispatch, toolz, h5py, logical-unification, h5netcdf, xarray, cons, xarray-einstats, etuples, miniKanren, arviz, pytensor, pymc\n",
      "Successfully installed arviz-0.21.0 cons-0.4.6 etuples-0.3.9 h5netcdf-1.6.3 h5py-3.14.0 logical-unification-0.4.6 miniKanren-1.0.5 multipledispatch-1.0.0 pymc-5.23.0 pytensor-2.31.6 toolz-1.0.0 xarray-2025.7.0 xarray-einstats-0.9.1\n",
      "Requirement already satisfied: arviz in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (0.21.0)\n",
      "Requirement already satisfied: setuptools>=60.0.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (75.8.2)\n",
      "Requirement already satisfied: matplotlib>=3.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.9.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (1.15.2)\n",
      "Requirement already satisfied: packaging in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (24.2)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (2.2.3)\n",
      "Requirement already satisfied: xarray>=2022.6.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (2025.7.0)\n",
      "Requirement already satisfied: h5netcdf>=1.0.2 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (4.14.0)\n",
      "Requirement already satisfied: xarray-einstats>=0.3 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from arviz) (0.9.1)\n",
      "Requirement already satisfied: h5py in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from h5netcdf>=1.0.2->arviz) (3.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from matplotlib>=3.5->arviz) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=1.5.0->arviz) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from pandas>=1.5.0->arviz) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib>=3.5->arviz) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dowhy\n",
    "!pip install pymc\n",
    "!pip install arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0222d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependências importadas com sucesso.\n",
      "✅ Dataset epidemiológico sintético criado com sucesso!\n",
      "📊 Dimensões: (2000, 17)\n",
      "🎯 Variável alvo: 'cardiovascular_event'\n",
      "📈 Prevalência de eventos cardiovasculares: 97.35%\n",
      "📈 Prevalência de diabetes: 74.12%\n",
      "📈 Prevalência de hipertensão: 73.97%\n",
      "💊 Taxa de tratamento: 42.37%\n",
      "Gerando dados clínicos simulados para demonstração...\n",
      "Agente Estatístico inicializado com sucesso. Dados carregados com 1000 linhas (após remover valores faltantes).\n",
      "\n",
      ">>> Iniciando análise do tipo: 'preditiva'\n",
      "   - Treinando modelo de Regressão Logística...\n",
      "--- RESULTADO DA ANÁLISE PREDITIVA ---\n",
      "Modelo de Regressão Logística treinado para prever 'cardiovascular_event'.\n",
      "As variáveis mais influentes (positiva ou negativamente) foram: smoking, bmi, idade, treatment.\n",
      "O gráfico mostra o peso de cada variável na decisão do modelo.\n",
      "Visualização gerada com 41104 bytes.\n",
      "\n",
      ">>> Iniciando análise do tipo: 'causal'\n",
      "   - Construindo modelo causal com DoWhy...\n",
      "propensity_score_matching\n",
      "\n",
      "--- RESULTADO DA INFERÊNCIA CAUSAL ---\n",
      "Análise de Inferência Causal concluída.\n",
      "Efeito causal médio do tratamento ('treatment') sobre o resultado ('cardiovascular_event') é de aproximadamente 0.0110.\n",
      "Isso sugere que o tratamento tem um efeito positivo no resultado, após controlar pelas variáveis de confusão.\n",
      "\n",
      ">>> Iniciando análise do tipo: 'probabilistica'\n",
      "   - Construindo modelo Bayesiano com PyMC (sintaxe moderna)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [intercept, betas]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 12 seconds.\n",
      "There were 2000 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTADO DA PROGRAMAÇÃO PROBABILÍSTICA ---\n",
      "Modelo de Regressão Logística Bayesiana treinado.\n",
      "O gráfico mostra as distribuições de credibilidade para os coeficientes das variáveis: idade, bmi, smoking, treatment.\n",
      "Isso nos permite quantificar a incerteza sobre o efeito de cada variável.\n",
      "Visualização gerada com 92692 bytes.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Arquivo: agente_estatistico.py\n",
    "# Descrição: Versão corrigida e simplificada do Agente de IA para análises estatísticas.\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libs para Análise Preditiva e XAI\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Libs para Inferência Causal\n",
    "from dowhy import CausalModel\n",
    "\n",
    "# Libs para Programação Probabilística (PyMC v4+)\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "# Importe sua classe de carregamento de dados (supondo que esteja em um arquivo dataset_loader.py)\n",
    "# from dataset_loader import DatasetLoader\n",
    "\n",
    "print(\"Dependências importadas com sucesso.\")\n",
    "\n",
    "class AgenteEstatistico:\n",
    "    \"\"\"\n",
    "    Um agente de IA que realiza diferentes tipos de análises estatísticas\n",
    "    em um determinado conjunto de dados.\n",
    "    \"\"\"\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Inicializa o agente com o conjunto de dados.\n",
    "        :param data: Um DataFrame do Pandas com os dados a serem analisados.\n",
    "        \"\"\"\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Os dados de entrada devem ser um DataFrame do Pandas.\")\n",
    "        # Lida com valores faltantes de forma simples para garantir que os modelos rodem\n",
    "        self.data = data.dropna().copy()\n",
    "        print(f\"Agente Estatístico inicializado com sucesso. Dados carregados com {self.data.shape[0]} linhas (após remover valores faltantes).\")\n",
    "\n",
    "    def analisar(self, analysis_type: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Ponto de entrada principal para realizar uma análise.\n",
    "        Funciona como um dispatcher que chama o método de análise apropriado.\n",
    "        \"\"\"\n",
    "        print(f\"\\n>>> Iniciando análise do tipo: '{analysis_type}'\")\n",
    "        if analysis_type == 'preditiva':\n",
    "            return self._run_predictive_analysis(**kwargs)\n",
    "        elif analysis_type == 'causal':\n",
    "            return self._run_causal_analysis(**kwargs)\n",
    "        elif analysis_type == 'probabilistica':\n",
    "            return self._run_probabilistic_analysis(**kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Tipo de análise desconhecido: {analysis_type}\")\n",
    "\n",
    "    def _run_predictive_analysis(self, target_column: str, feature_columns: list):\n",
    "        \"\"\"Realiza uma análise preditiva usando Regressão Logística e XAI.\"\"\"\n",
    "        print(\"   - Treinando modelo de Regressão Logística...\")\n",
    "        X = self.data[feature_columns]\n",
    "        y = self.data[target_column]\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000).fit(X, y)\n",
    "        \n",
    "        importances = pd.DataFrame(data=model.coef_[0], index=feature_columns, columns=[\"Importância\"])\n",
    "        importances = importances.sort_values(by=\"Importância\", ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=importances.index, y=importances['Importância'])\n",
    "        plt.title(\"XAI: Importância das Variáveis no Modelo Preditivo\")\n",
    "        plt.ylabel(\"Coeficiente da Regressão Logística\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format=\"png\", bbox_inches='tight')\n",
    "        viz_base64 = base64.b64encode(buf.getbuffer()).decode(\"ascii\")\n",
    "        plt.close()\n",
    "        \n",
    "        summary_text = (\n",
    "            f\"Modelo de Regressão Logística treinado para prever '{target_column}'.\\n\"\n",
    "            f\"As variáveis mais influentes (positiva ou negativamente) foram: {', '.join(importances.index)}.\\n\"\n",
    "            \"O gráfico mostra o peso de cada variável na decisão do modelo.\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"analysis_type\": \"Preditiva (com XAI)\",\n",
    "            \"summary\": summary_text,\n",
    "            \"visualization_b64\": viz_base64\n",
    "        }\n",
    "\n",
    "    def _run_causal_analysis(self, treatment_column: str, outcome_column: str, common_causes: list):\n",
    "        \"\"\"Realiza uma análise de inferência causal usando DoWhy.\"\"\"\n",
    "        print(\"   - Construindo modelo causal com DoWhy...\")\n",
    "        model = CausalModel(\n",
    "            data=self.data,\n",
    "            treatment=treatment_column,\n",
    "            outcome=outcome_column,\n",
    "            common_causes=common_causes\n",
    "        )\n",
    "        identified_estimand = model.identify_effect()\n",
    "        estimate = model.estimate_effect(\n",
    "            identified_estimand,\n",
    "            method_name=\"backdoor.propensity_score_matching\"\n",
    "        )\n",
    "        ate = estimate.value\n",
    "        \n",
    "        summary_text = (\n",
    "            f\"Análise de Inferência Causal concluída.\\n\"\n",
    "            f\"Efeito causal médio do tratamento ('{treatment_column}') sobre o resultado ('{outcome_column}') \"\n",
    "            f\"é de aproximadamente {ate:.4f}.\\n\"\n",
    "            f\"Isso sugere que o tratamento tem um efeito {'positivo' if ate > 0 else 'negativo'} no resultado, \"\n",
    "            \"após controlar pelas variáveis de confusão.\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"analysis_type\": \"Inferência Causal\",\n",
    "            \"summary\": summary_text,\n",
    "            \"estimated_effect\": ate\n",
    "        }\n",
    "\n",
    "    def _run_probabilistic_analysis(self, target_column: str, predictor_columns: list):\n",
    "        \"\"\"\n",
    "        Realiza uma análise probabilística usando PyMC (Regressão Logística Bayesiana).\n",
    "        *** ESTA FUNÇÃO FOI CORRIGIDA PARA USAR A SINTAXE MODERNA DO PYMC (v4+) ***\n",
    "        \"\"\"\n",
    "        print(\"   - Construindo modelo Bayesiano com PyMC (sintaxe moderna)...\")\n",
    "        \n",
    "        with pm.Model() as probabilistic_model:\n",
    "            # Define os priors (nossas crenças iniciais sobre os parâmetros)\n",
    "            # Priors não informativos (vagos) para deixar os dados falarem\n",
    "            intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "            \n",
    "            # Um coeficiente para cada variável preditora\n",
    "            betas = pm.Normal(\"betas\", mu=0, sigma=10, shape=len(predictor_columns))\n",
    "            \n",
    "            # Modelo linear\n",
    "            # Extrai os dados do DataFrame e os converte para um formato que o PyMC entende\n",
    "            predictors_data = self.data[predictor_columns].values\n",
    "            logit_p = intercept + pt.dot(predictors_data, betas)\n",
    "            \n",
    "            # Likelihood (como os dados são gerados)\n",
    "            y_obs = pm.Bernoulli(target_column, logit_p=logit_p, observed=self.data[target_column].values)\n",
    "            \n",
    "            # Amostragem do posterior\n",
    "            trace = pm.sample(2000, tune=1000, cores=1, random_seed=42)\n",
    "            \n",
    "        # Gera a visualização do resultado (distribuições a posteriori)\n",
    "        # O nome das variáveis no gráfico agora é 'betas'\n",
    "        az.plot_posterior(trace, var_names=['betas'])\n",
    "        plt.suptitle(\"Distribuições a Posteriori dos Coeficientes do Modelo\", y=1.02)\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format=\"png\", bbox_inches='tight')\n",
    "        viz_base64 = base64.b64encode(buf.getbuffer()).decode(\"ascii\")\n",
    "        plt.close()\n",
    "        \n",
    "        summary_text = (\n",
    "            \"Modelo de Regressão Logística Bayesiana treinado.\\n\"\n",
    "            f\"O gráfico mostra as distribuições de credibilidade para os coeficientes das variáveis: {', '.join(predictor_columns)}.\\n\"\n",
    "            \"Isso nos permite quantificar a incerteza sobre o efeito de cada variável.\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"analysis_type\": \"Programação Probabilística\",\n",
    "            \"summary\": summary_text,\n",
    "            \"visualization_b64\": viz_base64\n",
    "        }\n",
    "\n",
    "# --- FUNÇÃO DE EXECUÇÃO E DEMONSTRAÇÃO ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Supondo que a classe DatasetLoader está em um arquivo chamado dataset_loader.py\n",
    "    from datasets import DatasetLoader\n",
    "    loader = DatasetLoader()\n",
    "    dados_clinicos = loader.create_synthetic_epidemiological_data()\n",
    "    \n",
    "    # Para este exemplo, vamos gerar os dados aqui para que o script seja autocontido\n",
    "    print(\"Gerando dados clínicos simulados para demonstração...\")\n",
    "    np.random.seed(42)\n",
    "    n_patients = 1000\n",
    "    idade = np.random.normal(55, 18, n_patients)\n",
    "    sexo = np.random.binomial(1, 0.52, n_patients)\n",
    "    bmi = np.random.normal(26, 5, n_patients)\n",
    "    smoking = np.random.binomial(1, 0.15 + 0.1 * (sexo == 1), n_patients)\n",
    "    treatment_propensity = -2 + 0.02 * idade + 0.3 * smoking\n",
    "    treatment = (treatment_propensity + np.random.logistic(0, 1, n_patients) > 0).astype(int)\n",
    "    cv_risk = -10 + 0.08 * idade + 0.15 * bmi + 1.2 * smoking - 0.5 * treatment\n",
    "    cardiovascular_event = (cv_risk + np.random.logistic(0, 1, n_patients) > 0).astype(int)\n",
    "    dados_clinicos = pd.DataFrame({\n",
    "        'idade': idade, 'bmi': bmi, 'smoking': smoking, \n",
    "        'treatment': treatment, 'cardiovascular_event': cardiovascular_event\n",
    "    })\n",
    "\n",
    "    # 2. Inicializar o agente com os dados\n",
    "    agente_estatistico = AgenteEstatistico(dados_clinicos)\n",
    "    \n",
    "    # --- Executar e imprimir os resultados de cada tipo de análise ---\n",
    "    \n",
    "    # Análise Preditiva com XAI\n",
    "    resultado_preditivo = agente_estatistico.analisar(\n",
    "        'preditiva',\n",
    "        target_column='cardiovascular_event',\n",
    "        feature_columns=['idade', 'bmi', 'smoking', 'treatment']\n",
    "    )\n",
    "    print(\"--- RESULTADO DA ANÁLISE PREDITIVA ---\")\n",
    "    print(resultado_preditivo['summary'])\n",
    "    print(f\"Visualização gerada com {len(resultado_preditivo['visualization_b64'])} bytes.\")\n",
    "    \n",
    "    # Inferência Causal\n",
    "    resultado_causal = agente_estatistico.analisar(\n",
    "        'causal',\n",
    "        treatment_column='treatment',\n",
    "        outcome_column='cardiovascular_event',\n",
    "        common_causes=['idade', 'smoking'] # Idade e fumo são confundidores\n",
    "    )\n",
    "    print(\"\\n--- RESULTADO DA INFERÊNCIA CAUSAL ---\")\n",
    "    print(resultado_causal['summary'])\n",
    "    \n",
    "    # Programação Probabilística\n",
    "    resultado_probabilistico = agente_estatistico.analisar(\n",
    "        'probabilistica',\n",
    "        target_column='cardiovascular_event',\n",
    "        predictor_columns=['idade', 'bmi', 'smoking', 'treatment']\n",
    "    )\n",
    "    print(\"\\n--- RESULTADO DA PROGRAMAÇÃO PROBABILÍSTICA ---\")\n",
    "    print(resultado_probabilistico['summary'])\n",
    "    print(f\"Visualização gerada com {len(resultado_probabilistico['visualization_b64'])} bytes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad83ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependências importadas com sucesso.\n",
      "Gerando dados clínicos simulados para demonstração...\n",
      "Agente Estatístico inicializado com sucesso. Dados carregados com 1000 linhas (após remover valores faltantes).\n",
      "\n",
      ">>> Iniciando análise do tipo: 'preditiva'\n",
      "   - Treinando modelo de Regressão Logística...\n",
      "✅ Relatório salvo em: /home/danilo/repos/statistical_agent_medical_data/relatorio_preditivo.html\n",
      "\n",
      ">>> Iniciando análise do tipo: 'causal'\n",
      "   - Construindo modelo causal com DoWhy...\n",
      "propensity_score_matching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relatório salvo em: /home/danilo/repos/statistical_agent_medical_data/relatorio_causal.html\n",
      "\n",
      ">>> Iniciando análise do tipo: 'probabilistica'\n",
      "   - Construindo modelo Bayesiano com PyMC (sintaxe moderna)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [intercept, betas]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/danilo/anaconda3/envs/mestrado/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 13 seconds.\n",
      "There were 2000 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relatório salvo em: /home/danilo/repos/statistical_agent_medical_data/relatorio_probabilistico.html\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Arquivo: agente_estatistico.py\n",
    "# Descrição: Versão final que salva os resultados e visualizações em arquivos HTML.\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Libs para Análise Preditiva e XAI\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Libs para Inferência Causal\n",
    "from dowhy import CausalModel\n",
    "\n",
    "# Libs para Programação Probabilística (PyMC v4+)\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "print(\"Dependências importadas com sucesso.\")\n",
    "\n",
    "class AgenteEstatistico:\n",
    "    \"\"\"\n",
    "    Um agente de IA que realiza diferentes tipos de análises estatísticas\n",
    "    em um determinado conjunto de dados.\n",
    "    \"\"\"\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Inicializa o agente com o conjunto de dados.\n",
    "        :param data: Um DataFrame do Pandas com os dados a serem analisados.\n",
    "        \"\"\"\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Os dados de entrada devem ser um DataFrame do Pandas.\")\n",
    "        # Lida com valores faltantes de forma simples para garantir que os modelos rodem\n",
    "        self.data = data.dropna().copy()\n",
    "        print(f\"Agente Estatístico inicializado com sucesso. Dados carregados com {self.data.shape[0]} linhas (após remover valores faltantes).\")\n",
    "\n",
    "    def analisar(self, analysis_type: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Ponto de entrada principal para realizar uma análise.\n",
    "        Funciona como um dispatcher que chama o método de análise apropriado.\n",
    "        \"\"\"\n",
    "        print(f\"\\n>>> Iniciando análise do tipo: '{analysis_type}'\")\n",
    "        if analysis_type == 'preditiva':\n",
    "            return self._run_predictive_analysis(**kwargs)\n",
    "        elif analysis_type == 'causal':\n",
    "            return self._run_causal_analysis(**kwargs)\n",
    "        elif analysis_type == 'probabilistica':\n",
    "            return self._run_probabilistic_analysis(**kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Tipo de análise desconhecido: {analysis_type}\")\n",
    "\n",
    "    def _run_predictive_analysis(self, target_column: str, feature_columns: list):\n",
    "        \"\"\"Realiza uma análise preditiva usando Regressão Logística e XAI.\"\"\"\n",
    "        print(\"   - Treinando modelo de Regressão Logística...\")\n",
    "        X = self.data[feature_columns]\n",
    "        y = self.data[target_column]\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000).fit(X, y)\n",
    "        \n",
    "        importances = pd.DataFrame(data=model.coef_[0], index=feature_columns, columns=[\"Importância\"])\n",
    "        importances = importances.sort_values(by=\"Importância\", ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=importances.index, y=importances['Importância'])\n",
    "        plt.title(\"XAI: Importância das Variáveis no Modelo Preditivo\")\n",
    "        plt.ylabel(\"Coeficiente da Regressão Logística\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format=\"png\", bbox_inches='tight')\n",
    "        viz_base64 = base64.b64encode(buf.getbuffer()).decode(\"ascii\")\n",
    "        plt.close()\n",
    "        \n",
    "        summary_text = (\n",
    "            f\"Modelo de Regressão Logística treinado para prever '{target_column}'.\\n\"\n",
    "            f\"As variáveis mais influentes (positiva ou negativamente) foram: {', '.join(importances.index)}.\\n\"\n",
    "            \"O gráfico mostra o peso de cada variável na decisão do modelo.\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"analysis_type\": \"Preditiva (com XAI)\",\n",
    "            \"summary\": summary_text,\n",
    "            \"visualization_b64\": viz_base64\n",
    "        }\n",
    "\n",
    "    def _run_causal_analysis(self, treatment_column: str, outcome_column: str, common_causes: list):\n",
    "        \"\"\"Realiza uma análise de inferência causal usando DoWhy.\"\"\"\n",
    "        print(\"   - Construindo modelo causal com DoWhy...\")\n",
    "        model = CausalModel(\n",
    "            data=self.data,\n",
    "            treatment=treatment_column,\n",
    "            outcome=outcome_column,\n",
    "            common_causes=common_causes\n",
    "        )\n",
    "        identified_estimand = model.identify_effect()\n",
    "        estimate = model.estimate_effect(\n",
    "            identified_estimand,\n",
    "            method_name=\"backdoor.propensity_score_matching\"\n",
    "        )\n",
    "        ate = estimate.value\n",
    "        \n",
    "        summary_text = (\n",
    "            f\"Análise de Inferência Causal concluída.\\n\"\n",
    "            f\"Efeito causal médio do tratamento ('{treatment_column}') sobre o resultado ('{outcome_column}') \"\n",
    "            f\"é de aproximadamente {ate:.4f}.\\n\"\n",
    "            f\"Isso sugere que o tratamento tem um efeito {'positivo' if ate > 0 else 'negativo'} no resultado, \"\n",
    "            \"após controlar pelas variáveis de confusão.\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"analysis_type\": \"Inferência Causal\",\n",
    "            \"summary\": summary_text,\n",
    "            \"estimated_effect\": ate,\n",
    "            \"visualization_b64\": None # Análise causal não gera gráfico neste exemplo\n",
    "        }\n",
    "\n",
    "    def _run_probabilistic_analysis(self, target_column: str, predictor_columns: list):\n",
    "        \"\"\"\n",
    "        Realiza uma análise probabilística usando PyMC (Regressão Logística Bayesiana).\n",
    "        \"\"\"\n",
    "        print(\"   - Construindo modelo Bayesiano com PyMC (sintaxe moderna)...\")\n",
    "        \n",
    "        with pm.Model() as probabilistic_model:\n",
    "            intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
    "            betas = pm.Normal(\"betas\", mu=0, sigma=10, shape=len(predictor_columns))\n",
    "            predictors_data = self.data[predictor_columns].values\n",
    "            logit_p = intercept + pt.dot(predictors_data, betas)\n",
    "            y_obs = pm.Bernoulli(target_column, logit_p=logit_p, observed=self.data[target_column].values)\n",
    "            trace = pm.sample(2000, tune=1000, cores=1, random_seed=42)\n",
    "            \n",
    "        az.plot_posterior(trace, var_names=['betas'])\n",
    "        plt.suptitle(\"Distribuições a Posteriori dos Coeficientes do Modelo\", y=1.02)\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format=\"png\", bbox_inches='tight')\n",
    "        viz_base64 = base64.b64encode(buf.getbuffer()).decode(\"ascii\")\n",
    "        plt.close()\n",
    "        \n",
    "        summary_text = (\n",
    "            \"Modelo de Regressão Logística Bayesiana treinado.\\n\"\n",
    "            f\"O gráfico mostra as distribuições de credibilidade para os coeficientes das variáveis: {', '.join(predictor_columns)}.\\n\"\n",
    "            \"Isso nos permite quantificar a incerteza sobre o efeito de cada variável.\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"analysis_type\": \"Programação Probabilística\",\n",
    "            \"summary\": summary_text,\n",
    "            \"visualization_b64\": viz_base64\n",
    "        }\n",
    "\n",
    "# --- FUNÇÃO DE EXECUÇÃO E DEMONSTRAÇÃO ---\n",
    "\n",
    "def salvar_relatorio_html(resultado: dict, nome_arquivo: str):\n",
    "    \"\"\"\n",
    "    Salva o resultado de uma análise em um arquivo HTML simples para visualização.\n",
    "    \"\"\"\n",
    "    titulo = resultado.get(\"analysis_type\", \"Relatório de Análise\")\n",
    "    resumo = resultado.get(\"summary\", \"Nenhum resumo disponível.\")\n",
    "    viz_b64 = resultado.get(\"visualization_b64\")\n",
    "\n",
    "    # Converte quebras de linha do resumo para tags <br>\n",
    "    resumo_html = resumo.replace('\\n', '<br>')\n",
    "\n",
    "    # Cria o HTML para a imagem, se ela existir\n",
    "    imagem_html = \"\"\n",
    "    if viz_b64:\n",
    "        imagem_html = f'<h2>Visualização</h2>\\n<img src=\"data:image/png;base64,{viz_b64}\" alt=\"Gráfico da Análise\">'\n",
    "\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"pt-BR\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>{titulo}</title>\n",
    "        <style>\n",
    "            body {{ font-family: sans-serif; line-height: 1.6; margin: 40px; }}\n",
    "            h1, h2 {{ color: #333; }}\n",
    "            .container {{ max-width: 800px; margin: auto; padding: 20px; border: 1px solid #ddd; border-radius: 8px; }}\n",
    "            img {{ max-width: 100%; height: auto; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"container\">\n",
    "            <h1>{titulo}</h1>\n",
    "            <h2>Resumo da Análise</h2>\n",
    "            <p>{resumo_html}</p>\n",
    "            {imagem_html}\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(nome_arquivo, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "    print(f\"✅ Relatório salvo em: {os.path.abspath(nome_arquivo)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Gerando dados clínicos simulados para demonstração...\")\n",
    "    np.random.seed(42)\n",
    "    n_patients = 1000\n",
    "    idade = np.random.normal(55, 18, n_patients)\n",
    "    sexo = np.random.binomial(1, 0.52, n_patients)\n",
    "    bmi = np.random.normal(26, 5, n_patients)\n",
    "    smoking = np.random.binomial(1, 0.15 + 0.1 * (sexo == 1), n_patients)\n",
    "    treatment_propensity = -2 + 0.02 * idade + 0.3 * smoking\n",
    "    treatment = (treatment_propensity + np.random.logistic(0, 1, n_patients) > 0).astype(int)\n",
    "    cv_risk = -10 + 0.08 * idade + 0.15 * bmi + 1.2 * smoking - 0.5 * treatment\n",
    "    cardiovascular_event = (cv_risk + np.random.logistic(0, 1, n_patients) > 0).astype(int)\n",
    "    dados_clinicos = pd.DataFrame({\n",
    "        'idade': idade, 'bmi': bmi, 'smoking': smoking, \n",
    "        'treatment': treatment, 'cardiovascular_event': cardiovascular_event\n",
    "    })\n",
    "\n",
    "    agente_estatistico = AgenteEstatistico(dados_clinicos)\n",
    "    \n",
    "    # Análise Preditiva com XAI\n",
    "    resultado_preditivo = agente_estatistico.analisar(\n",
    "        'preditiva',\n",
    "        target_column='cardiovascular_event',\n",
    "        feature_columns=['idade', 'bmi', 'smoking', 'treatment']\n",
    "    )\n",
    "    salvar_relatorio_html(resultado_preditivo, \"relatorio_preditivo.html\")\n",
    "    \n",
    "    # Inferência Causal\n",
    "    resultado_causal = agente_estatistico.analisar(\n",
    "        'causal',\n",
    "        treatment_column='treatment',\n",
    "        outcome_column='cardiovascular_event',\n",
    "        common_causes=['idade', 'smoking']\n",
    "    )\n",
    "    salvar_relatorio_html(resultado_causal, \"relatorio_causal.html\")\n",
    "    \n",
    "    # Programação Probabilística\n",
    "    resultado_probabilistico = agente_estatistico.analisar(\n",
    "        'probabilistica',\n",
    "        target_column='cardiovascular_event',\n",
    "        predictor_columns=['idade', 'bmi', 'smoking', 'treatment']\n",
    "    )\n",
    "    salvar_relatorio_html(resultado_probabilistico, \"relatorio_probabilistico.html\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
